{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4LsknHQZ90k",
        "outputId": "93f5ed0b-3a1a-43cd-e55d-94eb34badce7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Types of Each Feature:\n",
            "Unnamed: 0        int64\n",
            "WTT             float64\n",
            "PTI             float64\n",
            "EQW             float64\n",
            "SBI             float64\n",
            "LQE             float64\n",
            "QWG             float64\n",
            "FDJ             float64\n",
            "PJF             float64\n",
            "HQE             float64\n",
            "NXJ             float64\n",
            "TARGET CLASS      int64\n",
            "dtype: object\n",
            "\n",
            "Summary of the Dataset:\n",
            "        Unnamed: 0          WTT          PTI          EQW          SBI  \\\n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
            "mean    499.500000     0.949682     1.114303     0.834127     0.682099   \n",
            "std     288.819436     0.289635     0.257085     0.291554     0.229645   \n",
            "min       0.000000     0.174412     0.441398     0.170924     0.045027   \n",
            "25%     249.750000     0.742358     0.942071     0.615451     0.515010   \n",
            "50%     499.500000     0.940475     1.118486     0.813264     0.676835   \n",
            "75%     749.250000     1.163295     1.307904     1.028340     0.834317   \n",
            "90%     899.100000     1.336612     1.441901     1.223127     0.983470   \n",
            "max     999.000000     1.721779     1.833757     1.722725     1.634884   \n",
            "\n",
            "               LQE          QWG          FDJ          PJF          HQE  \\\n",
            "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
            "mean      1.032336     0.943534     0.963422     1.071960     1.158251   \n",
            "std       0.243413     0.256121     0.255118     0.288982     0.293738   \n",
            "min       0.315307     0.262389     0.295228     0.299476     0.365157   \n",
            "25%       0.870855     0.761064     0.784407     0.866306     0.934340   \n",
            "50%       1.035824     0.941502     0.945333     1.065500     1.165556   \n",
            "75%       1.198270     1.123060     1.134852     1.283156     1.383173   \n",
            "90%       1.341138     1.277552     1.306497     1.452713     1.535520   \n",
            "max       1.650050     1.666902     1.713342     1.785420     1.885690   \n",
            "\n",
            "               NXJ  TARGET CLASS  \n",
            "count  1000.000000    1000.00000  \n",
            "mean      1.362725       0.50000  \n",
            "std       0.204225       0.50025  \n",
            "min       0.639693       0.00000  \n",
            "25%       1.222623       0.00000  \n",
            "50%       1.375368       0.50000  \n",
            "75%       1.504832       1.00000  \n",
            "90%       1.618096       1.00000  \n",
            "max       1.893950       1.00000  \n",
            "\n",
            "Names of Columns/Features in the Dataset:\n",
            "Index(['Unnamed: 0', 'WTT', 'PTI', 'EQW', 'SBI', 'LQE', 'QWG', 'FDJ', 'PJF',\n",
            "       'HQE', 'NXJ', 'TARGET CLASS'],\n",
            "      dtype='object')\n",
            "'target_column' not found in the DataFrame.\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 2: Load the classified dataset into a dataframe using pandas\n",
        "# Assuming 'data.csv' is the name of your dataset file\n",
        "df = pd.read_csv('Classified_Data.txt')\n",
        "\n",
        "# Step 3: Check the data types of each feature(column) in the dataset\n",
        "print(\"Data Types of Each Feature:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Step 4: Generate a summary of the dataset for min, max, stddev, quartile values for 25%,50%,75%,90%\n",
        "print(\"\\nSummary of the Dataset:\")\n",
        "print(df.describe(percentiles=[0.25, 0.50, 0.75, 0.90]))\n",
        "\n",
        "# Step 5: List the names of columns/features in the dataset\n",
        "print(\"\\nNames of Columns/Features in the Dataset:\")\n",
        "print(df.columns)\n",
        "\n",
        "# Step 6: Scale the features using StandardScaler and transform the data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Check if 'target_column' exists in the DataFrame\n",
        "if 'target_column' in df.columns:\n",
        "    scaled_data = scaler.fit_transform(df.drop(columns=['target_column']))\n",
        "    scaled_df = pd.DataFrame(scaled_data, columns=df.drop(columns=['target_column']).columns)\n",
        "    # Display the scaled dataset\n",
        "    print(\"\\nScaled Data:\")\n",
        "    print(scaled_df.head())\n",
        "else:\n",
        "    print(\"'target_column' not found in the DataFrame.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Step 1: Load the classified dataset into a dataframe using pandas\n",
        "df = pd.read_csv('Classified_Data.txt')  # Replace 'your_dataset.csv' with your dataset filename\n",
        "\n",
        "# Step 2: Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df.drop(columns=['TARGET CLASS']))\n",
        "scaled_df = pd.DataFrame(scaled_data, columns=df.drop(columns=['TARGET CLASS']).columns)\n",
        "\n",
        "# Step 3: Split the data into training and testing sets\n",
        "X = scaled_df  # Features\n",
        "y = df['TARGET CLASS']  # Target variable\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Apply the KNN Classifier model\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
        "\n",
        "# Step 5: Fit the data to the Classifier Model\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "print(\"Model training and fitting completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0onjocW4bF2M",
        "outputId": "7519be93-c538-4d07-b382-1f3f4acb6462"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training and fitting completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Step 1: Generate the confusion matrix\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Step 2: Generate the classification report\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC6U3OBZbyC0",
        "outputId": "0225f791-4b25-404c-d4b5-19b47211e4a9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[92  6]\n",
            " [ 4 98]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        98\n",
            "           1       0.94      0.96      0.95       102\n",
            "\n",
            "    accuracy                           0.95       200\n",
            "   macro avg       0.95      0.95      0.95       200\n",
            "weighted avg       0.95      0.95      0.95       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}